{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ExemplosPythonStanford.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/osmarbraz/exemplos_python/blob/master/ExemplosPythonStanford.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vx1EQOz6roMH"
      },
      "source": [
        "# Exemplo Análise Texto com Parser Stanford\n",
        "https://nlp.stanford.edu/software/\n",
        "\n",
        "-----------------------------------------\n",
        "**Guia Colab Iniciante:**\n",
        "\n",
        "https://medium.com/machina-sapiens/google-colab-guia-do-iniciante-334d70aad531\n",
        "\n",
        "**Documentação oficial:**\n",
        "\n",
        "https://colab.research.google.com/github/jakevdp/PythonDataScienceHandbook/blob/master/notebooks/01.01-Help-And-Documentation.ipynb\n",
        "\n",
        "**Características :**\n",
        "\n",
        "https://colab.research.google.com/notebooks/basic_features_overview.ipynb"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r9FYB2rr7SYO"
      },
      "source": [
        "\n",
        "**Frase Simples:**\n",
        "\n",
        "Frase1 = \"Era necessário que você comparecesse à reunião.\"\n",
        "\n",
        "Oracao 1 = Era necessário \n",
        "\n",
        "Oracao 2 = que você comparecesse à reunião. \n",
        "\n",
        "**Frase Complexa:**\n",
        "\n",
        "Frase2 = \"Estados anunciam flexibilização em época de alta circulação de vírus respiratórios, apontam séries históricas da Fiocruz.\"\n",
        "\n",
        "Oracao 1 = Estados anunciam flexibilização em época de alta circulação de vírus respiratórios, \n",
        "\n",
        "Oracao 2 = apontam séries históricas da Fiocruz.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PGMNz8ujnAkq"
      },
      "source": [
        "#frase = u\"Estou bem, mas não tenho certeza se viajarei para São Paulo amanhã às 8:30.\"\n",
        "#frase = \"Que é época de alta circulação de vírus respiratórios, apontam séries históricas da Fiocruz.\"\n",
        "#frase = u'Olá Professor Osmar, hoje teremos aula?'\n",
        "frase = u'Professor, como eu faço para empilhar um elemento de uma fila?'\n",
        "#frase = u'Olá Professor tudo bem? Como eu faço para Empilhar um elemento de uma Fila? Boa Tarde!'\n",
        "#frase = \"O cão roía o osso.\"\n",
        "#frase = \"O rato comeu o queijo.\"\n",
        "#frase = \"Maria foi fazer a feira\"\n",
        "#frase = \"João ama Maria.\"\n",
        "#frase = \"Quem descobriu o Brazil?\""
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yVlsEWyraXKV"
      },
      "source": [
        "# Instalação"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WTOl4Rs4b_Ag",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "031f0172-7cd8-43f2-c413-e78366957cf7"
      },
      "source": [
        "# Download the Stanford NLP tools\n",
        "!wget https://nlp.stanford.edu/software/stanford-ner-4.0.0.zip\n",
        "!wget https://nlp.stanford.edu/software/stanford-tagger-4.0.0.zip\n",
        "!wget https://nlp.stanford.edu/software/stanford-parser-4.0.0.zip\n",
        "\n",
        "# Extract the zip file.\n",
        "!unzip stanford-ner-4.0.0.zip \n",
        "!unzip stanford-tagger-4.0.0.zip\n",
        "!unzip stanford-parser-4.0.0.zip\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-11-29 11:32:36--  https://nlp.stanford.edu/software/stanford-ner-4.0.0.zip\n",
            "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 180643763 (172M) [application/zip]\n",
            "Saving to: ‘stanford-ner-4.0.0.zip’\n",
            "\n",
            "stanford-ner-4.0.0. 100%[===================>] 172.27M  4.42MB/s    in 30s     \n",
            "\n",
            "2020-11-29 11:33:06 (5.70 MB/s) - ‘stanford-ner-4.0.0.zip’ saved [180643763/180643763]\n",
            "\n",
            "--2020-11-29 11:33:06--  https://nlp.stanford.edu/software/stanford-tagger-4.0.0.zip\n",
            "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 78260695 (75M) [application/zip]\n",
            "Saving to: ‘stanford-tagger-4.0.0.zip’\n",
            "\n",
            "stanford-tagger-4.0 100%[===================>]  74.63M  6.72MB/s    in 12s     \n",
            "\n",
            "2020-11-29 11:33:19 (6.09 MB/s) - ‘stanford-tagger-4.0.0.zip’ saved [78260695/78260695]\n",
            "\n",
            "--2020-11-29 11:33:19--  https://nlp.stanford.edu/software/stanford-parser-4.0.0.zip\n",
            "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 182493647 (174M) [application/zip]\n",
            "Saving to: ‘stanford-parser-4.0.0.zip’\n",
            "\n",
            "stanford-parser-4.0 100%[===================>] 174.04M  32.0MB/s    in 8.5s    \n",
            "\n",
            "2020-11-29 11:33:28 (20.4 MB/s) - ‘stanford-parser-4.0.0.zip’ saved [182493647/182493647]\n",
            "\n",
            "Archive:  stanford-ner-4.0.0.zip\n",
            "   creating: stanford-ner-4.0.0/\n",
            "  inflating: stanford-ner-4.0.0/ner-gui.sh  \n",
            "  inflating: stanford-ner-4.0.0/build.xml  \n",
            "  inflating: stanford-ner-4.0.0/stanford-ner.jar  \n",
            "  inflating: stanford-ner-4.0.0/sample-conll-file.txt  \n",
            "  inflating: stanford-ner-4.0.0/README.txt  \n",
            "  inflating: stanford-ner-4.0.0/NERDemo.java  \n",
            "  inflating: stanford-ner-4.0.0/sample.ner.txt  \n",
            "  inflating: stanford-ner-4.0.0/ner.sh  \n",
            "  inflating: stanford-ner-4.0.0/LICENSE.txt  \n",
            "   creating: stanford-ner-4.0.0/lib/\n",
            "  inflating: stanford-ner-4.0.0/lib/joda-time.jar  \n",
            "  inflating: stanford-ner-4.0.0/lib/jollyday-0.4.9.jar  \n",
            "  inflating: stanford-ner-4.0.0/lib/stanford-ner-resources.jar  \n",
            "  inflating: stanford-ner-4.0.0/stanford-ner-4.0.0-sources.jar  \n",
            "  inflating: stanford-ner-4.0.0/sample.txt  \n",
            "  inflating: stanford-ner-4.0.0/ner-gui.command  \n",
            "  inflating: stanford-ner-4.0.0/ner.bat  \n",
            "  inflating: stanford-ner-4.0.0/ner-gui.bat  \n",
            "  inflating: stanford-ner-4.0.0/stanford-ner-4.0.0-javadoc.jar  \n",
            "   creating: stanford-ner-4.0.0/classifiers/\n",
            "  inflating: stanford-ner-4.0.0/classifiers/english.muc.7class.distsim.prop  \n",
            "  inflating: stanford-ner-4.0.0/classifiers/english.conll.4class.distsim.crf.ser.gz  \n",
            "  inflating: stanford-ner-4.0.0/classifiers/example.serialized.ncc.prop  \n",
            "  inflating: stanford-ner-4.0.0/classifiers/english.all.3class.distsim.prop  \n",
            "  inflating: stanford-ner-4.0.0/classifiers/english.muc.7class.distsim.crf.ser.gz  \n",
            "  inflating: stanford-ner-4.0.0/classifiers/english.conll.4class.distsim.prop  \n",
            "  inflating: stanford-ner-4.0.0/classifiers/english.all.3class.distsim.crf.ser.gz  \n",
            "  inflating: stanford-ner-4.0.0/classifiers/example.serialized.ncc.ncc.ser.gz  \n",
            "  inflating: stanford-ner-4.0.0/sample-w-time.txt  \n",
            "  inflating: stanford-ner-4.0.0/stanford-ner-4.0.0.jar  \n",
            "Archive:  stanford-tagger-4.0.0.zip\n",
            "   creating: stanford-tagger-4.0.0/\n",
            "  inflating: stanford-tagger-4.0.0/stanford-postagger-4.0.0-javadoc.jar  \n",
            "  inflating: stanford-tagger-4.0.0/stanford-postagger.bat  \n",
            "  inflating: stanford-tagger-4.0.0/sample-input.txt  \n",
            "  inflating: stanford-tagger-4.0.0/sample-output.txt  \n",
            "   creating: stanford-tagger-4.0.0/data/\n",
            "  inflating: stanford-tagger-4.0.0/data/enclitic-inflections.data  \n",
            "  inflating: stanford-tagger-4.0.0/stanford-postagger-gui.sh  \n",
            "  inflating: stanford-tagger-4.0.0/TaggerDemo.java  \n",
            "  inflating: stanford-tagger-4.0.0/stanford-postagger-4.0.0.jar  \n",
            "   creating: stanford-tagger-4.0.0/models/\n",
            "  inflating: stanford-tagger-4.0.0/models/arabic-train.tagger.props  \n",
            "  inflating: stanford-tagger-4.0.0/models/english-left3words-distsim.tagger.props  \n",
            "  inflating: stanford-tagger-4.0.0/models/arabic.tagger  \n",
            "  inflating: stanford-tagger-4.0.0/models/chinese-nodistsim.tagger.props  \n",
            "  inflating: stanford-tagger-4.0.0/models/README-Models.txt  \n",
            "  inflating: stanford-tagger-4.0.0/models/german-ud.tagger  \n",
            "  inflating: stanford-tagger-4.0.0/models/english-caseless-left3words-distsim.tagger.props  \n",
            "  inflating: stanford-tagger-4.0.0/models/chinese-distsim.tagger  \n",
            "  inflating: stanford-tagger-4.0.0/models/english-caseless-left3words-distsim.tagger  \n",
            "  inflating: stanford-tagger-4.0.0/models/arabic.tagger.props  \n",
            "  inflating: stanford-tagger-4.0.0/models/german-ud.tagger.props  \n",
            "  inflating: stanford-tagger-4.0.0/models/french-ud.tagger.props  \n",
            "  inflating: stanford-tagger-4.0.0/models/english-left3words-distsim.tagger  \n",
            "  inflating: stanford-tagger-4.0.0/models/english-bidirectional-distsim.tagger.props  \n",
            "  inflating: stanford-tagger-4.0.0/models/french-ud.tagger  \n",
            "  inflating: stanford-tagger-4.0.0/models/arabic-train.tagger  \n",
            "  inflating: stanford-tagger-4.0.0/models/spanish-ud.tagger  \n",
            "  inflating: stanford-tagger-4.0.0/models/english-bidirectional-distsim.tagger  \n",
            "  inflating: stanford-tagger-4.0.0/models/chinese-distsim.tagger.props  \n",
            "  inflating: stanford-tagger-4.0.0/models/spanish-ud.tagger.props  \n",
            "  inflating: stanford-tagger-4.0.0/models/chinese-nodistsim.tagger  \n",
            "  inflating: stanford-tagger-4.0.0/stanford-postagger.sh  \n",
            "  inflating: stanford-tagger-4.0.0/stanford-postagger-gui.bat  \n",
            "  inflating: stanford-tagger-4.0.0/README.txt  \n",
            "  inflating: stanford-tagger-4.0.0/build.xml  \n",
            "  inflating: stanford-tagger-4.0.0/TaggerDemo2.java  \n",
            "  inflating: stanford-tagger-4.0.0/stanford-postagger-4.0.0-sources.jar  \n",
            "  inflating: stanford-tagger-4.0.0/LICENSE.txt  \n",
            "  inflating: stanford-tagger-4.0.0/stanford-postagger.jar  \n",
            "Archive:  stanford-parser-4.0.0.zip\n",
            "   creating: stanford-parser-4.0.0/\n",
            "  inflating: stanford-parser-4.0.0/ShiftReduceDemo.java  \n",
            "  inflating: stanford-parser-4.0.0/lexparser-gui.command  \n",
            "  inflating: stanford-parser-4.0.0/ejml-core-0.38.jar  \n",
            "  inflating: stanford-parser-4.0.0/DependencyParserDemo.java  \n",
            "  inflating: stanford-parser-4.0.0/pom.xml  \n",
            "  inflating: stanford-parser-4.0.0/ejml-ddense-0.38-sources.jar  \n",
            "  inflating: stanford-parser-4.0.0/ejml-simple-0.38-sources.jar  \n",
            "  inflating: stanford-parser-4.0.0/lexparser.sh  \n",
            "  inflating: stanford-parser-4.0.0/lexparser-gui.bat  \n",
            "  inflating: stanford-parser-4.0.0/stanford-parser.jar  \n",
            "  inflating: stanford-parser-4.0.0/LICENSE.txt  \n",
            "  inflating: stanford-parser-4.0.0/stanford-parser-4.0.0-sources.jar  \n",
            "  inflating: stanford-parser-4.0.0/ejml-simple-0.38.jar  \n",
            "  inflating: stanford-parser-4.0.0/Makefile  \n",
            "  inflating: stanford-parser-4.0.0/lexparser-lang-train-test.sh  \n",
            "  inflating: stanford-parser-4.0.0/ParserDemo.java  \n",
            "  inflating: stanford-parser-4.0.0/lexparser-lang.sh  \n",
            "  inflating: stanford-parser-4.0.0/README.txt  \n",
            "  inflating: stanford-parser-4.0.0/stanford-parser-4.0.0-models.jar  \n",
            "   creating: stanford-parser-4.0.0/data/\n",
            " extracting: stanford-parser-4.0.0/data/english-onesent.txt  \n",
            "  inflating: stanford-parser-4.0.0/data/chinese-onesent-unseg-utf8.txt  \n",
            "  inflating: stanford-parser-4.0.0/data/testsent.txt  \n",
            "  inflating: stanford-parser-4.0.0/data/french-onesent.txt  \n",
            " extracting: stanford-parser-4.0.0/data/german-onesent.txt  \n",
            " extracting: stanford-parser-4.0.0/data/chinese-onesent-utf8.txt  \n",
            " extracting: stanford-parser-4.0.0/data/chinese-onesent-gb18030.txt  \n",
            "  inflating: stanford-parser-4.0.0/data/pos-sentences.txt  \n",
            " extracting: stanford-parser-4.0.0/data/chinese-onesent-unseg-gb18030.txt  \n",
            " extracting: stanford-parser-4.0.0/data/arabic-onesent-utf8.txt  \n",
            "   creating: stanford-parser-4.0.0/bin/\n",
            "  inflating: stanford-parser-4.0.0/bin/run-tb-preproc  \n",
            "  inflating: stanford-parser-4.0.0/bin/makeSerialized.csh  \n",
            "  inflating: stanford-parser-4.0.0/lexparser-gui.sh  \n",
            "  inflating: stanford-parser-4.0.0/ejml-ddense-0.38.jar  \n",
            "   creating: stanford-parser-4.0.0/conf/\n",
            "  inflating: stanford-parser-4.0.0/conf/atb-latest.conf  \n",
            "  inflating: stanford-parser-4.0.0/conf/ftb-latest.conf  \n",
            "  inflating: stanford-parser-4.0.0/slf4j-api-1.7.12-sources.jar  \n",
            "  inflating: stanford-parser-4.0.0/lexparser.bat  \n",
            "  inflating: stanford-parser-4.0.0/lexparser_lang.def  \n",
            "  inflating: stanford-parser-4.0.0/StanfordDependenciesManual.pdf  \n",
            "  inflating: stanford-parser-4.0.0/build.xml  \n",
            "  inflating: stanford-parser-4.0.0/README_dependencies.txt  \n",
            "  inflating: stanford-parser-4.0.0/slf4j-api.jar  \n",
            "  inflating: stanford-parser-4.0.0/ejml-core-0.38-sources.jar  \n",
            "  inflating: stanford-parser-4.0.0/stanford-parser-4.0.0-javadoc.jar  \n",
            "  inflating: stanford-parser-4.0.0/ParserDemo2.java  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LjvXcI95gu8o"
      },
      "source": [
        "https://phitchuria.wordpress.com/2018/10/11/python-nltk-phrase-structure-parsing-and-dependency-parsing-using-stanford-parser-on-nltk/\n",
        "\n",
        "https://www.analyticsvidhya.com/blog/2019/02/stanfordnlp-nlp-library-python/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y-9_OyHFq_jQ"
      },
      "source": [
        "# Análise da Estrutura da Frase"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ymvhICQQZ1V1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ff6a3f5e-7220-471f-8caf-14b8f277c786"
      },
      "source": [
        "import nltk\n",
        "from nltk.parse.stanford import StanfordParser\n",
        "\n",
        "# uma função para percorrer uma frase para encontrar os constituintes (folhas)\n",
        "# é escrito de forma recursiva, pode ser alterado para um loop\n",
        "def traverse_phrase(tree): \n",
        "    for subtree in tree:\n",
        "        if type(subtree) == nltk.tree.Tree:\n",
        "            traverse_phrase(subtree)\n",
        "        else:\n",
        "            print( \"constituent : \" + subtree )\n",
        "\n",
        "# uma função para percorrer uma árvore para encontrar NP\n",
        "# é escrito de forma recursiva, pode ser alterado para um loop\n",
        "def traverse_tree(tree):\n",
        "    for subtree in tree:\n",
        "        if type(subtree) == nltk.tree.Tree:\n",
        "            if subtree.label() == 'NP':\n",
        "                print(\"\\n[Noun Phrase]\")\n",
        "                traverse_phrase(subtree)\n",
        "            else :\n",
        "                traverse_tree(subtree)\n",
        "\n",
        "\n",
        "stanford_parser_dir = '/content/stanford-parser-4.0.0/' # mude aqui para o seu diretório\n",
        "path_to_models = stanford_parser_dir  + \"stanford-parser-4.0.0-models.jar\"\n",
        "path_to_jar = stanford_parser_dir  + \"stanford-parser.jar\"\n",
        "\n",
        "sentence = (frase)\n",
        "\n",
        "# Analisador da estrutura da frase\n",
        "parser=StanfordParser(path_to_models, path_to_jar)\n",
        "\n",
        "print( \"\\n\\nResultado da análise da estrutura da frase - imprimirá apenas NPs (frases nominais)\")\n",
        "parsed_sentence = parser.raw_parse(sentence)\n",
        "traverse_tree(parsed_sentence)\n",
        " \n",
        "print( \"\\n\\nResultado da análise da estrutura da frase - será impresso em formato de árvore e desenhado\")\n",
        "parsed_sentence = parser.raw_parse(sentence) \n",
        "tree = parsed_sentence.__next__()\n",
        "print( tree )\n",
        "#tree.draw()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "Resultado da análise da estrutura da frase - imprimirá apenas NPs (frases nominais)\n",
            "\n",
            "[Noun Phrase]\n",
            "constituent : Professor\n",
            "\n",
            "[Noun Phrase]\n",
            "constituent : como\n",
            "constituent : eu\n",
            "constituent : faço\n",
            "constituent : para\n",
            "constituent : empilhar\n",
            "constituent : um\n",
            "constituent : elemento\n",
            "constituent : de\n",
            "constituent : uma\n",
            "constituent : fila\n",
            "\n",
            "\n",
            "Resultado da análise da estrutura da frase - será impresso em formato de árvore e desenhado\n",
            "(ROOT\n",
            "  (FRAG\n",
            "    (NP (NNP Professor))\n",
            "    (, ,)\n",
            "    (NP\n",
            "      (NN como)\n",
            "      (NN eu)\n",
            "      (NN faço)\n",
            "      (NN para)\n",
            "      (NN empilhar)\n",
            "      (NN um)\n",
            "      (NN elemento)\n",
            "      (NNP de)\n",
            "      (NN uma)\n",
            "      (NN fila))\n",
            "    (. ?)))\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q8sn3DC4rHyz"
      },
      "source": [
        "# Análise de Dependência"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r_bp8T8wg-L9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "371bb01e-5f96-4eb8-d1e8-59c1b3a487b3"
      },
      "source": [
        "import nltk\n",
        "from nltk.parse.stanford import StanfordDependencyParser\n",
        "\n",
        "sentence = (frase)\n",
        "\n",
        "# Dependency Parsing\n",
        "dep_parser = StanfordDependencyParser(path_to_models, path_to_jar)\n",
        "\n",
        "print(\"Frase=\" + frase)\n",
        "\n",
        "print( \"\\n\\nResultado da análise de dependência - no formato CoNLL\")\n",
        "dep_parsed_sentence = dep_parser.raw_parse(sentence)\n",
        "deps = dep_parsed_sentence.__next__()\n",
        "print( deps.to_conll(10) )\n",
        "\n",
        "# to_conll(10) will return the result in a format as follows:\n",
        "# id word lemma ctag tag feats head(head's id) rel(syntactic relation)\n",
        "# return values that is unknown will be shown as '_'\n",
        "# tag and ctag are considered to be equal\n",
        "\n",
        "print( \"\\n\\nResultado de análise de dependência - em uma lista de formato TRIPLE(head,relation,dependent)\")\n",
        "print (list(deps.triples()))\n",
        "\n",
        "print( \"\\n\\nResultado da Análise de Dependência - no formato head:?, relation:?, dependent:?\")\n",
        "for ( word1, pos1), rel, (word2, pos2) in list(deps.triples()):\n",
        "    print( \"head: \"+word1 + \", relation: \" + rel + \", dependent: \" + word2 )"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Frase=Professor, como eu faço para empilhar um elemento de uma fila?\n",
            "\n",
            "\n",
            "Resultado da análise de dependência - no formato CoNLL\n",
            "1\tProfessor\t_\tNNP\tNNP\t_\t0\troot\t_\t_\n",
            "3\tcomo\t_\tNN\tNN\t_\t12\tcompound\t_\t_\n",
            "4\teu\t_\tNN\tNN\t_\t12\tcompound\t_\t_\n",
            "5\tfaço\t_\tNN\tNN\t_\t12\tcompound\t_\t_\n",
            "6\tpara\t_\tNN\tNN\t_\t12\tcompound\t_\t_\n",
            "7\tempilhar\t_\tNN\tNN\t_\t12\tcompound\t_\t_\n",
            "8\tum\t_\tNN\tNN\t_\t12\tcompound\t_\t_\n",
            "9\telemento\t_\tNN\tNN\t_\t12\tcompound\t_\t_\n",
            "10\tde\t_\tNNP\tNNP\t_\t12\tcompound\t_\t_\n",
            "11\tuma\t_\tNN\tNN\t_\t12\tcompound\t_\t_\n",
            "12\tfila\t_\tNN\tNN\t_\t1\tappos\t_\t_\n",
            "\n",
            "\n",
            "\n",
            "Resultado de análise de dependência - em uma lista de formato TRIPLE(head,relation,dependent)\n",
            "[(('Professor', 'NNP'), 'appos', ('fila', 'NN')), (('fila', 'NN'), 'compound', ('como', 'NN')), (('fila', 'NN'), 'compound', ('eu', 'NN')), (('fila', 'NN'), 'compound', ('faço', 'NN')), (('fila', 'NN'), 'compound', ('para', 'NN')), (('fila', 'NN'), 'compound', ('empilhar', 'NN')), (('fila', 'NN'), 'compound', ('um', 'NN')), (('fila', 'NN'), 'compound', ('elemento', 'NN')), (('fila', 'NN'), 'compound', ('de', 'NNP')), (('fila', 'NN'), 'compound', ('uma', 'NN'))]\n",
            "\n",
            "\n",
            "Resultado da Análise de Dependência - no formato head:?, relation:?, dependent:?\n",
            "head: Professor, relation: appos, dependent: fila\n",
            "head: fila, relation: compound, dependent: como\n",
            "head: fila, relation: compound, dependent: eu\n",
            "head: fila, relation: compound, dependent: faço\n",
            "head: fila, relation: compound, dependent: para\n",
            "head: fila, relation: compound, dependent: empilhar\n",
            "head: fila, relation: compound, dependent: um\n",
            "head: fila, relation: compound, dependent: elemento\n",
            "head: fila, relation: compound, dependent: de\n",
            "head: fila, relation: compound, dependent: uma\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}